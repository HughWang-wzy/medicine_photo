{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "random.seed(3407)\n",
    "torch.manual_seed(3407)\n",
    "torch.cuda.manual_seed_all(3407)\n",
    "numpy.random.seed(3407)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.16.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src in dataset: size= <built-in method size of Tensor object at 0x7ff3da679c60> mode= <built-in method mode of Tensor object at 0x7ff3da679c60>\n",
      "tgt in dataset: size= <built-in method size of Image object at 0x7ff3da679d50> mode= <built-in method mode of Image object at 0x7ff3da679d50>\n",
      "src shape in dataloader: torch.Size([4, 1, 256, 256])\n",
      "tgt shape in dataloader: torch.Size([4, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from data import get_dataloader, get_normparam\n",
    "!python data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.4454502735091958 0.1425343463182748\n",
      "test: 0.42473554009837755 0.14345889458209693\n"
     ]
    }
   ],
   "source": [
    "mean_train, std_train = get_normparam('/data/NEU_Seg-main', True)\n",
    "mean_test, std_test = get_normparam('/data/NEU_Seg-main', False)\n",
    "print('train:', mean_train, std_train)\n",
    "print('test:', mean_test, std_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "          REBNCONV-4         [-1, 64, 256, 256]               0\n",
      "            Conv2d-5         [-1, 16, 256, 256]           9,232\n",
      "       BatchNorm2d-6         [-1, 16, 256, 256]              32\n",
      "              ReLU-7         [-1, 16, 256, 256]               0\n",
      "          REBNCONV-8         [-1, 16, 256, 256]               0\n",
      "         MaxPool2d-9         [-1, 16, 128, 128]               0\n",
      "           Conv2d-10         [-1, 16, 128, 128]           2,320\n",
      "      BatchNorm2d-11         [-1, 16, 128, 128]              32\n",
      "             ReLU-12         [-1, 16, 128, 128]               0\n",
      "         REBNCONV-13         [-1, 16, 128, 128]               0\n",
      "        MaxPool2d-14           [-1, 16, 64, 64]               0\n",
      "           Conv2d-15           [-1, 16, 64, 64]           2,320\n",
      "      BatchNorm2d-16           [-1, 16, 64, 64]              32\n",
      "             ReLU-17           [-1, 16, 64, 64]               0\n",
      "         REBNCONV-18           [-1, 16, 64, 64]               0\n",
      "        MaxPool2d-19           [-1, 16, 32, 32]               0\n",
      "           Conv2d-20           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-21           [-1, 16, 32, 32]              32\n",
      "             ReLU-22           [-1, 16, 32, 32]               0\n",
      "         REBNCONV-23           [-1, 16, 32, 32]               0\n",
      "        MaxPool2d-24           [-1, 16, 16, 16]               0\n",
      "           Conv2d-25           [-1, 16, 16, 16]           2,320\n",
      "      BatchNorm2d-26           [-1, 16, 16, 16]              32\n",
      "             ReLU-27           [-1, 16, 16, 16]               0\n",
      "         REBNCONV-28           [-1, 16, 16, 16]               0\n",
      "        MaxPool2d-29             [-1, 16, 8, 8]               0\n",
      "           Conv2d-30             [-1, 16, 8, 8]           2,320\n",
      "      BatchNorm2d-31             [-1, 16, 8, 8]              32\n",
      "             ReLU-32             [-1, 16, 8, 8]               0\n",
      "         REBNCONV-33             [-1, 16, 8, 8]               0\n",
      "           Conv2d-34             [-1, 16, 8, 8]           2,320\n",
      "      BatchNorm2d-35             [-1, 16, 8, 8]              32\n",
      "             ReLU-36             [-1, 16, 8, 8]               0\n",
      "         REBNCONV-37             [-1, 16, 8, 8]               0\n",
      "           Conv2d-38             [-1, 16, 8, 8]           4,624\n",
      "      BatchNorm2d-39             [-1, 16, 8, 8]              32\n",
      "             ReLU-40             [-1, 16, 8, 8]               0\n",
      "         REBNCONV-41             [-1, 16, 8, 8]               0\n",
      "           Conv2d-42           [-1, 16, 16, 16]           4,624\n",
      "      BatchNorm2d-43           [-1, 16, 16, 16]              32\n",
      "             ReLU-44           [-1, 16, 16, 16]               0\n",
      "         REBNCONV-45           [-1, 16, 16, 16]               0\n",
      "           Conv2d-46           [-1, 16, 32, 32]           4,624\n",
      "      BatchNorm2d-47           [-1, 16, 32, 32]              32\n",
      "             ReLU-48           [-1, 16, 32, 32]               0\n",
      "         REBNCONV-49           [-1, 16, 32, 32]               0\n",
      "           Conv2d-50           [-1, 16, 64, 64]           4,624\n",
      "      BatchNorm2d-51           [-1, 16, 64, 64]              32\n",
      "             ReLU-52           [-1, 16, 64, 64]               0\n",
      "         REBNCONV-53           [-1, 16, 64, 64]               0\n",
      "           Conv2d-54         [-1, 16, 128, 128]           4,624\n",
      "      BatchNorm2d-55         [-1, 16, 128, 128]              32\n",
      "             ReLU-56         [-1, 16, 128, 128]               0\n",
      "         REBNCONV-57         [-1, 16, 128, 128]               0\n",
      "           Conv2d-58         [-1, 64, 256, 256]          18,496\n",
      "      BatchNorm2d-59         [-1, 64, 256, 256]             128\n",
      "             ReLU-60         [-1, 64, 256, 256]               0\n",
      "         REBNCONV-61         [-1, 64, 256, 256]               0\n",
      "             RSU7-62         [-1, 64, 256, 256]               0\n",
      "        MaxPool2d-63         [-1, 64, 128, 128]               0\n",
      "           Conv2d-64         [-1, 64, 128, 128]          36,928\n",
      "      BatchNorm2d-65         [-1, 64, 128, 128]             128\n",
      "             ReLU-66         [-1, 64, 128, 128]               0\n",
      "         REBNCONV-67         [-1, 64, 128, 128]               0\n",
      "           Conv2d-68         [-1, 16, 128, 128]           9,232\n",
      "      BatchNorm2d-69         [-1, 16, 128, 128]              32\n",
      "             ReLU-70         [-1, 16, 128, 128]               0\n",
      "         REBNCONV-71         [-1, 16, 128, 128]               0\n",
      "        MaxPool2d-72           [-1, 16, 64, 64]               0\n",
      "           Conv2d-73           [-1, 16, 64, 64]           2,320\n",
      "      BatchNorm2d-74           [-1, 16, 64, 64]              32\n",
      "             ReLU-75           [-1, 16, 64, 64]               0\n",
      "         REBNCONV-76           [-1, 16, 64, 64]               0\n",
      "        MaxPool2d-77           [-1, 16, 32, 32]               0\n",
      "           Conv2d-78           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-79           [-1, 16, 32, 32]              32\n",
      "             ReLU-80           [-1, 16, 32, 32]               0\n",
      "         REBNCONV-81           [-1, 16, 32, 32]               0\n",
      "        MaxPool2d-82           [-1, 16, 16, 16]               0\n",
      "           Conv2d-83           [-1, 16, 16, 16]           2,320\n",
      "      BatchNorm2d-84           [-1, 16, 16, 16]              32\n",
      "             ReLU-85           [-1, 16, 16, 16]               0\n",
      "         REBNCONV-86           [-1, 16, 16, 16]               0\n",
      "        MaxPool2d-87             [-1, 16, 8, 8]               0\n",
      "           Conv2d-88             [-1, 16, 8, 8]           2,320\n",
      "      BatchNorm2d-89             [-1, 16, 8, 8]              32\n",
      "             ReLU-90             [-1, 16, 8, 8]               0\n",
      "         REBNCONV-91             [-1, 16, 8, 8]               0\n",
      "           Conv2d-92             [-1, 16, 8, 8]           2,320\n",
      "      BatchNorm2d-93             [-1, 16, 8, 8]              32\n",
      "             ReLU-94             [-1, 16, 8, 8]               0\n",
      "         REBNCONV-95             [-1, 16, 8, 8]               0\n",
      "           Conv2d-96             [-1, 16, 8, 8]           4,624\n",
      "      BatchNorm2d-97             [-1, 16, 8, 8]              32\n",
      "             ReLU-98             [-1, 16, 8, 8]               0\n",
      "         REBNCONV-99             [-1, 16, 8, 8]               0\n",
      "          Conv2d-100           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-101           [-1, 16, 16, 16]              32\n",
      "            ReLU-102           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-103           [-1, 16, 16, 16]               0\n",
      "          Conv2d-104           [-1, 16, 32, 32]           4,624\n",
      "     BatchNorm2d-105           [-1, 16, 32, 32]              32\n",
      "            ReLU-106           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-107           [-1, 16, 32, 32]               0\n",
      "          Conv2d-108           [-1, 16, 64, 64]           4,624\n",
      "     BatchNorm2d-109           [-1, 16, 64, 64]              32\n",
      "            ReLU-110           [-1, 16, 64, 64]               0\n",
      "        REBNCONV-111           [-1, 16, 64, 64]               0\n",
      "          Conv2d-112         [-1, 64, 128, 128]          18,496\n",
      "     BatchNorm2d-113         [-1, 64, 128, 128]             128\n",
      "            ReLU-114         [-1, 64, 128, 128]               0\n",
      "        REBNCONV-115         [-1, 64, 128, 128]               0\n",
      "            RSU6-116         [-1, 64, 128, 128]               0\n",
      "       MaxPool2d-117           [-1, 64, 64, 64]               0\n",
      "          Conv2d-118           [-1, 64, 64, 64]          36,928\n",
      "     BatchNorm2d-119           [-1, 64, 64, 64]             128\n",
      "            ReLU-120           [-1, 64, 64, 64]               0\n",
      "        REBNCONV-121           [-1, 64, 64, 64]               0\n",
      "          Conv2d-122           [-1, 16, 64, 64]           9,232\n",
      "     BatchNorm2d-123           [-1, 16, 64, 64]              32\n",
      "            ReLU-124           [-1, 16, 64, 64]               0\n",
      "        REBNCONV-125           [-1, 16, 64, 64]               0\n",
      "       MaxPool2d-126           [-1, 16, 32, 32]               0\n",
      "          Conv2d-127           [-1, 16, 32, 32]           2,320\n",
      "     BatchNorm2d-128           [-1, 16, 32, 32]              32\n",
      "            ReLU-129           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-130           [-1, 16, 32, 32]               0\n",
      "       MaxPool2d-131           [-1, 16, 16, 16]               0\n",
      "          Conv2d-132           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-133           [-1, 16, 16, 16]              32\n",
      "            ReLU-134           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-135           [-1, 16, 16, 16]               0\n",
      "       MaxPool2d-136             [-1, 16, 8, 8]               0\n",
      "          Conv2d-137             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-138             [-1, 16, 8, 8]              32\n",
      "            ReLU-139             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-140             [-1, 16, 8, 8]               0\n",
      "          Conv2d-141             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-142             [-1, 16, 8, 8]              32\n",
      "            ReLU-143             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-144             [-1, 16, 8, 8]               0\n",
      "          Conv2d-145             [-1, 16, 8, 8]           4,624\n",
      "     BatchNorm2d-146             [-1, 16, 8, 8]              32\n",
      "            ReLU-147             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-148             [-1, 16, 8, 8]               0\n",
      "          Conv2d-149           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-150           [-1, 16, 16, 16]              32\n",
      "            ReLU-151           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-152           [-1, 16, 16, 16]               0\n",
      "          Conv2d-153           [-1, 16, 32, 32]           4,624\n",
      "     BatchNorm2d-154           [-1, 16, 32, 32]              32\n",
      "            ReLU-155           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-156           [-1, 16, 32, 32]               0\n",
      "          Conv2d-157           [-1, 64, 64, 64]          18,496\n",
      "     BatchNorm2d-158           [-1, 64, 64, 64]             128\n",
      "            ReLU-159           [-1, 64, 64, 64]               0\n",
      "        REBNCONV-160           [-1, 64, 64, 64]               0\n",
      "            RSU5-161           [-1, 64, 64, 64]               0\n",
      "       MaxPool2d-162           [-1, 64, 32, 32]               0\n",
      "          Conv2d-163           [-1, 64, 32, 32]          36,928\n",
      "     BatchNorm2d-164           [-1, 64, 32, 32]             128\n",
      "            ReLU-165           [-1, 64, 32, 32]               0\n",
      "        REBNCONV-166           [-1, 64, 32, 32]               0\n",
      "          Conv2d-167           [-1, 16, 32, 32]           9,232\n",
      "     BatchNorm2d-168           [-1, 16, 32, 32]              32\n",
      "            ReLU-169           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-170           [-1, 16, 32, 32]               0\n",
      "       MaxPool2d-171           [-1, 16, 16, 16]               0\n",
      "          Conv2d-172           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-173           [-1, 16, 16, 16]              32\n",
      "            ReLU-174           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-175           [-1, 16, 16, 16]               0\n",
      "       MaxPool2d-176             [-1, 16, 8, 8]               0\n",
      "          Conv2d-177             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-178             [-1, 16, 8, 8]              32\n",
      "            ReLU-179             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-180             [-1, 16, 8, 8]               0\n",
      "          Conv2d-181             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-182             [-1, 16, 8, 8]              32\n",
      "            ReLU-183             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-184             [-1, 16, 8, 8]               0\n",
      "          Conv2d-185             [-1, 16, 8, 8]           4,624\n",
      "     BatchNorm2d-186             [-1, 16, 8, 8]              32\n",
      "            ReLU-187             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-188             [-1, 16, 8, 8]               0\n",
      "          Conv2d-189           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-190           [-1, 16, 16, 16]              32\n",
      "            ReLU-191           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-192           [-1, 16, 16, 16]               0\n",
      "          Conv2d-193           [-1, 64, 32, 32]          18,496\n",
      "     BatchNorm2d-194           [-1, 64, 32, 32]             128\n",
      "            ReLU-195           [-1, 64, 32, 32]               0\n",
      "        REBNCONV-196           [-1, 64, 32, 32]               0\n",
      "            RSU4-197           [-1, 64, 32, 32]               0\n",
      "       MaxPool2d-198           [-1, 64, 16, 16]               0\n",
      "          Conv2d-199           [-1, 64, 16, 16]          36,928\n",
      "     BatchNorm2d-200           [-1, 64, 16, 16]             128\n",
      "            ReLU-201           [-1, 64, 16, 16]               0\n",
      "        REBNCONV-202           [-1, 64, 16, 16]               0\n",
      "          Conv2d-203           [-1, 16, 16, 16]           9,232\n",
      "     BatchNorm2d-204           [-1, 16, 16, 16]              32\n",
      "            ReLU-205           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-206           [-1, 16, 16, 16]               0\n",
      "          Conv2d-207           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-208           [-1, 16, 16, 16]              32\n",
      "            ReLU-209           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-210           [-1, 16, 16, 16]               0\n",
      "          Conv2d-211           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-212           [-1, 16, 16, 16]              32\n",
      "            ReLU-213           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-214           [-1, 16, 16, 16]               0\n",
      "          Conv2d-215           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-216           [-1, 16, 16, 16]              32\n",
      "            ReLU-217           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-218           [-1, 16, 16, 16]               0\n",
      "          Conv2d-219           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-220           [-1, 16, 16, 16]              32\n",
      "            ReLU-221           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-222           [-1, 16, 16, 16]               0\n",
      "          Conv2d-223           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-224           [-1, 16, 16, 16]              32\n",
      "            ReLU-225           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-226           [-1, 16, 16, 16]               0\n",
      "          Conv2d-227           [-1, 64, 16, 16]          18,496\n",
      "     BatchNorm2d-228           [-1, 64, 16, 16]             128\n",
      "            ReLU-229           [-1, 64, 16, 16]               0\n",
      "        REBNCONV-230           [-1, 64, 16, 16]               0\n",
      "           RSU4F-231           [-1, 64, 16, 16]               0\n",
      "       MaxPool2d-232             [-1, 64, 8, 8]               0\n",
      "          Conv2d-233             [-1, 64, 8, 8]          36,928\n",
      "     BatchNorm2d-234             [-1, 64, 8, 8]             128\n",
      "            ReLU-235             [-1, 64, 8, 8]               0\n",
      "        REBNCONV-236             [-1, 64, 8, 8]               0\n",
      "          Conv2d-237             [-1, 16, 8, 8]           9,232\n",
      "     BatchNorm2d-238             [-1, 16, 8, 8]              32\n",
      "            ReLU-239             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-240             [-1, 16, 8, 8]               0\n",
      "          Conv2d-241             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-242             [-1, 16, 8, 8]              32\n",
      "            ReLU-243             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-244             [-1, 16, 8, 8]               0\n",
      "          Conv2d-245             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-246             [-1, 16, 8, 8]              32\n",
      "            ReLU-247             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-248             [-1, 16, 8, 8]               0\n",
      "          Conv2d-249             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-250             [-1, 16, 8, 8]              32\n",
      "            ReLU-251             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-252             [-1, 16, 8, 8]               0\n",
      "          Conv2d-253             [-1, 16, 8, 8]           4,624\n",
      "     BatchNorm2d-254             [-1, 16, 8, 8]              32\n",
      "            ReLU-255             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-256             [-1, 16, 8, 8]               0\n",
      "          Conv2d-257             [-1, 16, 8, 8]           4,624\n",
      "     BatchNorm2d-258             [-1, 16, 8, 8]              32\n",
      "            ReLU-259             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-260             [-1, 16, 8, 8]               0\n",
      "          Conv2d-261             [-1, 64, 8, 8]          18,496\n",
      "     BatchNorm2d-262             [-1, 64, 8, 8]             128\n",
      "            ReLU-263             [-1, 64, 8, 8]               0\n",
      "        REBNCONV-264             [-1, 64, 8, 8]               0\n",
      "           RSU4F-265             [-1, 64, 8, 8]               0\n",
      "          Conv2d-266           [-1, 64, 16, 16]          73,792\n",
      "     BatchNorm2d-267           [-1, 64, 16, 16]             128\n",
      "            ReLU-268           [-1, 64, 16, 16]               0\n",
      "        REBNCONV-269           [-1, 64, 16, 16]               0\n",
      "          Conv2d-270           [-1, 16, 16, 16]           9,232\n",
      "     BatchNorm2d-271           [-1, 16, 16, 16]              32\n",
      "            ReLU-272           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-273           [-1, 16, 16, 16]               0\n",
      "          Conv2d-274           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-275           [-1, 16, 16, 16]              32\n",
      "            ReLU-276           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-277           [-1, 16, 16, 16]               0\n",
      "          Conv2d-278           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-279           [-1, 16, 16, 16]              32\n",
      "            ReLU-280           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-281           [-1, 16, 16, 16]               0\n",
      "          Conv2d-282           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-283           [-1, 16, 16, 16]              32\n",
      "            ReLU-284           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-285           [-1, 16, 16, 16]               0\n",
      "          Conv2d-286           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-287           [-1, 16, 16, 16]              32\n",
      "            ReLU-288           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-289           [-1, 16, 16, 16]               0\n",
      "          Conv2d-290           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-291           [-1, 16, 16, 16]              32\n",
      "            ReLU-292           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-293           [-1, 16, 16, 16]               0\n",
      "          Conv2d-294           [-1, 64, 16, 16]          18,496\n",
      "     BatchNorm2d-295           [-1, 64, 16, 16]             128\n",
      "            ReLU-296           [-1, 64, 16, 16]               0\n",
      "        REBNCONV-297           [-1, 64, 16, 16]               0\n",
      "           RSU4F-298           [-1, 64, 16, 16]               0\n",
      "          Conv2d-299           [-1, 64, 32, 32]          73,792\n",
      "     BatchNorm2d-300           [-1, 64, 32, 32]             128\n",
      "            ReLU-301           [-1, 64, 32, 32]               0\n",
      "        REBNCONV-302           [-1, 64, 32, 32]               0\n",
      "          Conv2d-303           [-1, 16, 32, 32]           9,232\n",
      "     BatchNorm2d-304           [-1, 16, 32, 32]              32\n",
      "            ReLU-305           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-306           [-1, 16, 32, 32]               0\n",
      "       MaxPool2d-307           [-1, 16, 16, 16]               0\n",
      "          Conv2d-308           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-309           [-1, 16, 16, 16]              32\n",
      "            ReLU-310           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-311           [-1, 16, 16, 16]               0\n",
      "       MaxPool2d-312             [-1, 16, 8, 8]               0\n",
      "          Conv2d-313             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-314             [-1, 16, 8, 8]              32\n",
      "            ReLU-315             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-316             [-1, 16, 8, 8]               0\n",
      "          Conv2d-317             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-318             [-1, 16, 8, 8]              32\n",
      "            ReLU-319             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-320             [-1, 16, 8, 8]               0\n",
      "          Conv2d-321             [-1, 16, 8, 8]           4,624\n",
      "     BatchNorm2d-322             [-1, 16, 8, 8]              32\n",
      "            ReLU-323             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-324             [-1, 16, 8, 8]               0\n",
      "          Conv2d-325           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-326           [-1, 16, 16, 16]              32\n",
      "            ReLU-327           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-328           [-1, 16, 16, 16]               0\n",
      "          Conv2d-329           [-1, 64, 32, 32]          18,496\n",
      "     BatchNorm2d-330           [-1, 64, 32, 32]             128\n",
      "            ReLU-331           [-1, 64, 32, 32]               0\n",
      "        REBNCONV-332           [-1, 64, 32, 32]               0\n",
      "            RSU4-333           [-1, 64, 32, 32]               0\n",
      "          Conv2d-334           [-1, 64, 64, 64]          73,792\n",
      "     BatchNorm2d-335           [-1, 64, 64, 64]             128\n",
      "            ReLU-336           [-1, 64, 64, 64]               0\n",
      "        REBNCONV-337           [-1, 64, 64, 64]               0\n",
      "          Conv2d-338           [-1, 16, 64, 64]           9,232\n",
      "     BatchNorm2d-339           [-1, 16, 64, 64]              32\n",
      "            ReLU-340           [-1, 16, 64, 64]               0\n",
      "        REBNCONV-341           [-1, 16, 64, 64]               0\n",
      "       MaxPool2d-342           [-1, 16, 32, 32]               0\n",
      "          Conv2d-343           [-1, 16, 32, 32]           2,320\n",
      "     BatchNorm2d-344           [-1, 16, 32, 32]              32\n",
      "            ReLU-345           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-346           [-1, 16, 32, 32]               0\n",
      "       MaxPool2d-347           [-1, 16, 16, 16]               0\n",
      "          Conv2d-348           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-349           [-1, 16, 16, 16]              32\n",
      "            ReLU-350           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-351           [-1, 16, 16, 16]               0\n",
      "       MaxPool2d-352             [-1, 16, 8, 8]               0\n",
      "          Conv2d-353             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-354             [-1, 16, 8, 8]              32\n",
      "            ReLU-355             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-356             [-1, 16, 8, 8]               0\n",
      "          Conv2d-357             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-358             [-1, 16, 8, 8]              32\n",
      "            ReLU-359             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-360             [-1, 16, 8, 8]               0\n",
      "          Conv2d-361             [-1, 16, 8, 8]           4,624\n",
      "     BatchNorm2d-362             [-1, 16, 8, 8]              32\n",
      "            ReLU-363             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-364             [-1, 16, 8, 8]               0\n",
      "          Conv2d-365           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-366           [-1, 16, 16, 16]              32\n",
      "            ReLU-367           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-368           [-1, 16, 16, 16]               0\n",
      "          Conv2d-369           [-1, 16, 32, 32]           4,624\n",
      "     BatchNorm2d-370           [-1, 16, 32, 32]              32\n",
      "            ReLU-371           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-372           [-1, 16, 32, 32]               0\n",
      "          Conv2d-373           [-1, 64, 64, 64]          18,496\n",
      "     BatchNorm2d-374           [-1, 64, 64, 64]             128\n",
      "            ReLU-375           [-1, 64, 64, 64]               0\n",
      "        REBNCONV-376           [-1, 64, 64, 64]               0\n",
      "            RSU5-377           [-1, 64, 64, 64]               0\n",
      "          Conv2d-378         [-1, 64, 128, 128]          73,792\n",
      "     BatchNorm2d-379         [-1, 64, 128, 128]             128\n",
      "            ReLU-380         [-1, 64, 128, 128]               0\n",
      "        REBNCONV-381         [-1, 64, 128, 128]               0\n",
      "          Conv2d-382         [-1, 16, 128, 128]           9,232\n",
      "     BatchNorm2d-383         [-1, 16, 128, 128]              32\n",
      "            ReLU-384         [-1, 16, 128, 128]               0\n",
      "        REBNCONV-385         [-1, 16, 128, 128]               0\n",
      "       MaxPool2d-386           [-1, 16, 64, 64]               0\n",
      "          Conv2d-387           [-1, 16, 64, 64]           2,320\n",
      "     BatchNorm2d-388           [-1, 16, 64, 64]              32\n",
      "            ReLU-389           [-1, 16, 64, 64]               0\n",
      "        REBNCONV-390           [-1, 16, 64, 64]               0\n",
      "       MaxPool2d-391           [-1, 16, 32, 32]               0\n",
      "          Conv2d-392           [-1, 16, 32, 32]           2,320\n",
      "     BatchNorm2d-393           [-1, 16, 32, 32]              32\n",
      "            ReLU-394           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-395           [-1, 16, 32, 32]               0\n",
      "       MaxPool2d-396           [-1, 16, 16, 16]               0\n",
      "          Conv2d-397           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-398           [-1, 16, 16, 16]              32\n",
      "            ReLU-399           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-400           [-1, 16, 16, 16]               0\n",
      "       MaxPool2d-401             [-1, 16, 8, 8]               0\n",
      "          Conv2d-402             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-403             [-1, 16, 8, 8]              32\n",
      "            ReLU-404             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-405             [-1, 16, 8, 8]               0\n",
      "          Conv2d-406             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-407             [-1, 16, 8, 8]              32\n",
      "            ReLU-408             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-409             [-1, 16, 8, 8]               0\n",
      "          Conv2d-410             [-1, 16, 8, 8]           4,624\n",
      "     BatchNorm2d-411             [-1, 16, 8, 8]              32\n",
      "            ReLU-412             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-413             [-1, 16, 8, 8]               0\n",
      "          Conv2d-414           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-415           [-1, 16, 16, 16]              32\n",
      "            ReLU-416           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-417           [-1, 16, 16, 16]               0\n",
      "          Conv2d-418           [-1, 16, 32, 32]           4,624\n",
      "     BatchNorm2d-419           [-1, 16, 32, 32]              32\n",
      "            ReLU-420           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-421           [-1, 16, 32, 32]               0\n",
      "          Conv2d-422           [-1, 16, 64, 64]           4,624\n",
      "     BatchNorm2d-423           [-1, 16, 64, 64]              32\n",
      "            ReLU-424           [-1, 16, 64, 64]               0\n",
      "        REBNCONV-425           [-1, 16, 64, 64]               0\n",
      "          Conv2d-426         [-1, 64, 128, 128]          18,496\n",
      "     BatchNorm2d-427         [-1, 64, 128, 128]             128\n",
      "            ReLU-428         [-1, 64, 128, 128]               0\n",
      "        REBNCONV-429         [-1, 64, 128, 128]               0\n",
      "            RSU6-430         [-1, 64, 128, 128]               0\n",
      "          Conv2d-431         [-1, 64, 256, 256]          73,792\n",
      "     BatchNorm2d-432         [-1, 64, 256, 256]             128\n",
      "            ReLU-433         [-1, 64, 256, 256]               0\n",
      "        REBNCONV-434         [-1, 64, 256, 256]               0\n",
      "          Conv2d-435         [-1, 16, 256, 256]           9,232\n",
      "     BatchNorm2d-436         [-1, 16, 256, 256]              32\n",
      "            ReLU-437         [-1, 16, 256, 256]               0\n",
      "        REBNCONV-438         [-1, 16, 256, 256]               0\n",
      "       MaxPool2d-439         [-1, 16, 128, 128]               0\n",
      "          Conv2d-440         [-1, 16, 128, 128]           2,320\n",
      "     BatchNorm2d-441         [-1, 16, 128, 128]              32\n",
      "            ReLU-442         [-1, 16, 128, 128]               0\n",
      "        REBNCONV-443         [-1, 16, 128, 128]               0\n",
      "       MaxPool2d-444           [-1, 16, 64, 64]               0\n",
      "          Conv2d-445           [-1, 16, 64, 64]           2,320\n",
      "     BatchNorm2d-446           [-1, 16, 64, 64]              32\n",
      "            ReLU-447           [-1, 16, 64, 64]               0\n",
      "        REBNCONV-448           [-1, 16, 64, 64]               0\n",
      "       MaxPool2d-449           [-1, 16, 32, 32]               0\n",
      "          Conv2d-450           [-1, 16, 32, 32]           2,320\n",
      "     BatchNorm2d-451           [-1, 16, 32, 32]              32\n",
      "            ReLU-452           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-453           [-1, 16, 32, 32]               0\n",
      "       MaxPool2d-454           [-1, 16, 16, 16]               0\n",
      "          Conv2d-455           [-1, 16, 16, 16]           2,320\n",
      "     BatchNorm2d-456           [-1, 16, 16, 16]              32\n",
      "            ReLU-457           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-458           [-1, 16, 16, 16]               0\n",
      "       MaxPool2d-459             [-1, 16, 8, 8]               0\n",
      "          Conv2d-460             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-461             [-1, 16, 8, 8]              32\n",
      "            ReLU-462             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-463             [-1, 16, 8, 8]               0\n",
      "          Conv2d-464             [-1, 16, 8, 8]           2,320\n",
      "     BatchNorm2d-465             [-1, 16, 8, 8]              32\n",
      "            ReLU-466             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-467             [-1, 16, 8, 8]               0\n",
      "          Conv2d-468             [-1, 16, 8, 8]           4,624\n",
      "     BatchNorm2d-469             [-1, 16, 8, 8]              32\n",
      "            ReLU-470             [-1, 16, 8, 8]               0\n",
      "        REBNCONV-471             [-1, 16, 8, 8]               0\n",
      "          Conv2d-472           [-1, 16, 16, 16]           4,624\n",
      "     BatchNorm2d-473           [-1, 16, 16, 16]              32\n",
      "            ReLU-474           [-1, 16, 16, 16]               0\n",
      "        REBNCONV-475           [-1, 16, 16, 16]               0\n",
      "          Conv2d-476           [-1, 16, 32, 32]           4,624\n",
      "     BatchNorm2d-477           [-1, 16, 32, 32]              32\n",
      "            ReLU-478           [-1, 16, 32, 32]               0\n",
      "        REBNCONV-479           [-1, 16, 32, 32]               0\n",
      "          Conv2d-480           [-1, 16, 64, 64]           4,624\n",
      "     BatchNorm2d-481           [-1, 16, 64, 64]              32\n",
      "            ReLU-482           [-1, 16, 64, 64]               0\n",
      "        REBNCONV-483           [-1, 16, 64, 64]               0\n",
      "          Conv2d-484         [-1, 16, 128, 128]           4,624\n",
      "     BatchNorm2d-485         [-1, 16, 128, 128]              32\n",
      "            ReLU-486         [-1, 16, 128, 128]               0\n",
      "        REBNCONV-487         [-1, 16, 128, 128]               0\n",
      "          Conv2d-488         [-1, 64, 256, 256]          18,496\n",
      "     BatchNorm2d-489         [-1, 64, 256, 256]             128\n",
      "            ReLU-490         [-1, 64, 256, 256]               0\n",
      "        REBNCONV-491         [-1, 64, 256, 256]               0\n",
      "            RSU7-492         [-1, 64, 256, 256]               0\n",
      "          Conv2d-493          [-1, 4, 256, 256]           2,308\n",
      "          Conv2d-494          [-1, 4, 128, 128]           2,308\n",
      "          Conv2d-495            [-1, 4, 64, 64]           2,308\n",
      "          Conv2d-496            [-1, 4, 32, 32]           2,308\n",
      "          Conv2d-497            [-1, 4, 16, 16]           2,308\n",
      "          Conv2d-498              [-1, 4, 8, 8]           2,308\n",
      "          Conv2d-499          [-1, 4, 256, 256]             100\n",
      "================================================================\n",
      "Total params: 1,140,508\n",
      "Trainable params: 1,140,508\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 933.35\n",
      "Params size (MB): 4.35\n",
      "Estimated Total Size (MB): 937.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from u2net import U2NETP\n",
    "model = U2NETP(1, 4).cuda()\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 256, 256))\n",
    "# from torch import rand\n",
    "# src = rand((1, 1, 256, 256)).cuda()\n",
    "# tgt = model(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 1140508\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: avgloss= 0.433606523946421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: avgloss= 0.2930463346198112 avgious= [0.9044163583083882, 0.0, 0.5776205451603534, 0.3136621265712651] miou= 0.29709422391053947\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: avgloss= 0.304277792869025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: avgloss= 0.259687062620651 avgious= [0.9201488421101062, 0.03629287443284004, 0.6537769055211334, 0.367598887132172] miou= 0.3525562223620485\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: avgloss= 0.2723679526505486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: avgloss= 0.2543224661976897 avgious= [0.9238764745714739, 0.014359051916080626, 0.6743468898696227, 0.4677588908067105] miou= 0.3854882775308046\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: avgloss= 0.26618422891031823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: avgloss= 0.22822102540771344 avgious= [0.9302835784302652, 0.18131753978034362, 0.693066258703503, 0.536349704468542] miou= 0.47024450098412957\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  84%|████████▍ | 254/302 [01:30<00:18,  2.64it/s]"
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch, test_one_epoch, CELoss\n",
    "import transform as T\n",
    "from u2net import U2NETP\n",
    "model = U2NETP(1, 4).cuda()\n",
    "print('model params:', sum(p.numel() for p in model.parameters()))\n",
    "root = '/data/NEU_Seg-main'\n",
    "trans_train = T.Compose([\n",
    "    T.RandomCrop((0.3, 1.), (0.5, 2.)),\n",
    "    T.Normalize(mean_train, std_train),\n",
    "    T.RandomRotate((-180, 180), p=1.),\n",
    "    T.RandomFlip(),\n",
    "    T.Resize((256, 256)),\n",
    "    T.GaussianNoise(0.01),\n",
    "])\n",
    "trans_test = T.Compose([\n",
    "    T.Normalize(mean_test, std_test),\n",
    "    T.Resize((256, 256)),\n",
    "])\n",
    "train_dataloader = get_dataloader(root, istrain=True, batch_size=12, trans=trans_train)\n",
    "test_dataloader = get_dataloader(root, istrain=False, batch_size=1, trans=trans_test)\n",
    "critirion = CELoss(reduction='mean').cuda()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "\n",
    "for epochIdx in range(30):\n",
    "    print(epochIdx + 1)\n",
    "    train_one_epoch(model, train_dataloader, critirion, optimizer)\n",
    "    if epochIdx % 1 == 0:\n",
    "        test_one_epoch(model, test_dataloader, critirion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0916",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
